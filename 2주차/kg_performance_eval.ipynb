{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aa8e31f4",
   "metadata": {},
   "source": [
    "# KG 성능 비교 실험 (ROUGE 기반 평가)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "61d3a3a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from rouge_score import rouge_scorer\n",
    "\n",
    "# 데이터 불러오기\n",
    "kg = pd.read_csv(\"kg_triples_test.csv\")\n",
    "test_df = pd.read_csv(\"test.csv\")\n",
    "\n",
    "# 트리플 결합 텍스트 만들기\n",
    "kg[\"triple_text\"] = kg[\"subject\"] + \" \" + kg[\"predicate\"] + \" \" + kg[\"object\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ac6233a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 간단한 유사도 기반 KG 검색 함수\n",
    "def find_relevant_kg(text, kg_texts, top_k=3):\n",
    "    matches = []\n",
    "    for t in kg_texts:\n",
    "        score = sum([1 for w in t.split() if w in text])\n",
    "        matches.append((t, score))\n",
    "    matches.sort(key=lambda x: x[1], reverse=True)\n",
    "    return [x[0] for x in matches[:top_k]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d55bbbf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 프롬프트 구성 함수\n",
    "def build_prompt(text, kg_hits):\n",
    "    context = \"\\n\".join(kg_hits)\n",
    "    return f\"다음은 참고 지식입니다:\\n{context}\\n\\n사용자 입력: {text}\\n답변:\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d974c404",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROUGE 평가 함수\n",
    "def evaluate_with_rouge(predictions, references):\n",
    "    scorer = rouge_scorer.RougeScorer(['rougeL'], use_stemmer=True)\n",
    "    scores = [scorer.score(ref, pred)[\"rougeL\"].fmeasure for pred, ref in zip(predictions, references)]\n",
    "    return sum(scores) / len(scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c2a94795",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'input'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\User\\lsm40\\anaconda3\\envs\\min24\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3804\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3805\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3806\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mindex.pyx:167\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mindex.pyx:196\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7081\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7089\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mKeyError\u001b[39m: 'input'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      4\u001b[39m sample = test_df.sample(\u001b[32m10\u001b[39m, random_state=\u001b[32m42\u001b[39m)\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m# 1. KG 없이 (baseline)\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m preds_no_kg = [\u001b[33m\"\u001b[39m\u001b[33m답변: \u001b[39m\u001b[33m\"\u001b[39m + text[:\u001b[32m20\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m text \u001b[38;5;129;01min\u001b[39;00m \u001b[43msample\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43minput\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m]\n\u001b[32m      9\u001b[39m \u001b[38;5;66;03m# 2. KG 사용\u001b[39;00m\n\u001b[32m     10\u001b[39m preds_with_kg = []\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\User\\lsm40\\anaconda3\\envs\\min24\\Lib\\site-packages\\pandas\\core\\frame.py:4102\u001b[39m, in \u001b[36mDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   4100\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.columns.nlevels > \u001b[32m1\u001b[39m:\n\u001b[32m   4101\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._getitem_multilevel(key)\n\u001b[32m-> \u001b[39m\u001b[32m4102\u001b[39m indexer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4103\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[32m   4104\u001b[39m     indexer = [indexer]\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\User\\lsm40\\anaconda3\\envs\\min24\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3807\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   3808\u001b[39m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc.Iterable)\n\u001b[32m   3809\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[32m   3810\u001b[39m     ):\n\u001b[32m   3811\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[32m-> \u001b[39m\u001b[32m3812\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m   3813\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m   3814\u001b[39m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[32m   3815\u001b[39m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[32m   3816\u001b[39m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[32m   3817\u001b[39m     \u001b[38;5;28mself\u001b[39m._check_indexing_error(key)\n",
      "\u001b[31mKeyError\u001b[39m: 'input'"
     ]
    }
   ],
   "source": [
    "from random import randint\n",
    "\n",
    "# 샘플 10개 추출\n",
    "sample = test_df.sample(10, random_state=42)\n",
    "\n",
    "# 1. KG 없이 (baseline)\n",
    "preds_no_kg = [\"답변: \" + text[:20] for text in sample[\"input\"]]\n",
    "\n",
    "# 2. KG 사용\n",
    "preds_with_kg = []\n",
    "for text in sample[\"input\"]:\n",
    "    hits = find_relevant_kg(text, kg[\"triple_text\"])\n",
    "    prompt = build_prompt(text, hits)\n",
    "    preds_with_kg.append(\"답변: \" + text[:20] + \" (지식반영)\")\n",
    "\n",
    "# 평가\n",
    "rouge_no_kg = evaluate_with_rouge(preds_no_kg, sample[\"output\"])\n",
    "rouge_with_kg = evaluate_with_rouge(preds_with_kg, sample[\"output\"])\n",
    "\n",
    "print(f\"KG 미사용 시 ROUGE-L: {rouge_no_kg:.4f}\")\n",
    "print(f\"KG 사용 시 ROUGE-L: {rouge_with_kg:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "22f11a7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📌 질문: 라이스 페이퍼의 두께나 구성이 일반적이지 않아 조금 놀랐습니다. 아마, 식사량을 충분히 하는 것이 목표였을건데, 이로 인해 월남쌈의 질감이나 맛을 느끼는 부분에서 조금 힘들었습니다. 개인적으로는 훠궈 육수는 조금 아쉬움이 남았지만, 다른 메뉴들 중에서는 고기가 빼어난 맛을 보였습니다.\n",
      "\n",
      "[프롬프트 - KG 미사용]\n",
      " 질문: 라이스 페이퍼의 두께나 구성이 일반적이지 않아 조금 놀랐습니다. 아마, 식사량을 충분히 하는 것이 목표였을건데, 이로 인해 월남쌈의 질감이나 맛을 느끼는 부분에서 조금 힘들었습니다. 개인적으로는 훠궈 육수는 조금 아쉬움이 남았지만, 다른 메뉴들 중에서는 고기가 빼어난 맛을 보였습니다.\n",
      "답변:\n",
      "\n",
      "[프롬프트 - KG 사용]\n",
      " 질문: 라이스 페이퍼의 두께나 구성이 일반적이지 않아 조금 놀랐습니다. 아마, 식사량을 충분히 하는 것이 목표였을건데, 이로 인해 월남쌈의 질감이나 맛을 느끼는 부분에서 조금 힘들었습니다. 개인적으로는 훠궈 육수는 조금 아쉬움이 남았지만, 다른 메뉴들 중에서는 고기가 빼어난 맛을 보였습니다.\n",
      "배경지식:\n",
      "- 사용자 질문한다 다른 사람의 의도\n",
      "답변:\n",
      "\n",
      "🤖 [KG 미사용 답변]\n",
      "\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 2] 지정된 파일을 찾을 수 없습니다",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[24]\u001b[39m\u001b[32m, line 52\u001b[39m\n\u001b[32m     50\u001b[39m \u001b[38;5;66;03m# ✅ 8. Ollama 실행 및 출력 결과\u001b[39;00m\n\u001b[32m     51\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m🤖 [KG 미사용 답변]\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m52\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[43mrun_ollama\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt_no_kg\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m     54\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m🤖 [KG 사용 답변]\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     55\u001b[39m \u001b[38;5;28mprint\u001b[39m(run_ollama(prompt_kg))\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[24]\u001b[39m\u001b[32m, line 28\u001b[39m, in \u001b[36mrun_ollama\u001b[39m\u001b[34m(prompt, model)\u001b[39m\n\u001b[32m     27\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mrun_ollama\u001b[39m(prompt, model=\u001b[33m\"\u001b[39m\u001b[33mllama3\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m---> \u001b[39m\u001b[32m28\u001b[39m     result = \u001b[43msubprocess\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     29\u001b[39m \u001b[43m        \u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mollama\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     30\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m=\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mutf-8\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     31\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstdout\u001b[49m\u001b[43m=\u001b[49m\u001b[43msubprocess\u001b[49m\u001b[43m.\u001b[49m\u001b[43mPIPE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     32\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstderr\u001b[49m\u001b[43m=\u001b[49m\u001b[43msubprocess\u001b[49m\u001b[43m.\u001b[49m\u001b[43mPIPE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     33\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m30\u001b[39;49m\n\u001b[32m     34\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     35\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m result.stdout.decode(\u001b[33m\"\u001b[39m\u001b[33mutf-8\u001b[39m\u001b[33m\"\u001b[39m).strip()\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\User\\lsm40\\anaconda3\\envs\\min24\\Lib\\subprocess.py:556\u001b[39m, in \u001b[36mrun\u001b[39m\u001b[34m(input, capture_output, timeout, check, *popenargs, **kwargs)\u001b[39m\n\u001b[32m    553\u001b[39m     kwargs[\u001b[33m'\u001b[39m\u001b[33mstdout\u001b[39m\u001b[33m'\u001b[39m] = PIPE\n\u001b[32m    554\u001b[39m     kwargs[\u001b[33m'\u001b[39m\u001b[33mstderr\u001b[39m\u001b[33m'\u001b[39m] = PIPE\n\u001b[32m--> \u001b[39m\u001b[32m556\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mPopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43mpopenargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m process:\n\u001b[32m    557\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    558\u001b[39m         stdout, stderr = process.communicate(\u001b[38;5;28minput\u001b[39m, timeout=timeout)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\User\\lsm40\\anaconda3\\envs\\min24\\Lib\\subprocess.py:1038\u001b[39m, in \u001b[36mPopen.__init__\u001b[39m\u001b[34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, user, group, extra_groups, encoding, errors, text, umask, pipesize, process_group)\u001b[39m\n\u001b[32m   1034\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.text_mode:\n\u001b[32m   1035\u001b[39m             \u001b[38;5;28mself\u001b[39m.stderr = io.TextIOWrapper(\u001b[38;5;28mself\u001b[39m.stderr,\n\u001b[32m   1036\u001b[39m                     encoding=encoding, errors=errors)\n\u001b[32m-> \u001b[39m\u001b[32m1038\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_execute_child\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexecutable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreexec_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclose_fds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1039\u001b[39m \u001b[43m                        \u001b[49m\u001b[43mpass_fds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcwd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1040\u001b[39m \u001b[43m                        \u001b[49m\u001b[43mstartupinfo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreationflags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshell\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1041\u001b[39m \u001b[43m                        \u001b[49m\u001b[43mp2cread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp2cwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1042\u001b[39m \u001b[43m                        \u001b[49m\u001b[43mc2pread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc2pwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1043\u001b[39m \u001b[43m                        \u001b[49m\u001b[43merrread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1044\u001b[39m \u001b[43m                        \u001b[49m\u001b[43mrestore_signals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1045\u001b[39m \u001b[43m                        \u001b[49m\u001b[43mgid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mumask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1046\u001b[39m \u001b[43m                        \u001b[49m\u001b[43mstart_new_session\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprocess_group\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1047\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[32m   1048\u001b[39m     \u001b[38;5;66;03m# Cleanup if the child failed starting.\u001b[39;00m\n\u001b[32m   1049\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mfilter\u001b[39m(\u001b[38;5;28;01mNone\u001b[39;00m, (\u001b[38;5;28mself\u001b[39m.stdin, \u001b[38;5;28mself\u001b[39m.stdout, \u001b[38;5;28mself\u001b[39m.stderr)):\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\User\\lsm40\\anaconda3\\envs\\min24\\Lib\\subprocess.py:1550\u001b[39m, in \u001b[36mPopen._execute_child\u001b[39m\u001b[34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, unused_restore_signals, unused_gid, unused_gids, unused_uid, unused_umask, unused_start_new_session, unused_process_group)\u001b[39m\n\u001b[32m   1548\u001b[39m \u001b[38;5;66;03m# Start the process\u001b[39;00m\n\u001b[32m   1549\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1550\u001b[39m     hp, ht, pid, tid = \u001b[43m_winapi\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCreateProcess\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexecutable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1551\u001b[39m \u001b[43m                             \u001b[49m\u001b[38;5;66;43;03m# no special security\u001b[39;49;00m\n\u001b[32m   1552\u001b[39m \u001b[43m                             \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1553\u001b[39m \u001b[43m                             \u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mclose_fds\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1554\u001b[39m \u001b[43m                             \u001b[49m\u001b[43mcreationflags\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1555\u001b[39m \u001b[43m                             \u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1556\u001b[39m \u001b[43m                             \u001b[49m\u001b[43mcwd\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1557\u001b[39m \u001b[43m                             \u001b[49m\u001b[43mstartupinfo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1558\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m   1559\u001b[39m     \u001b[38;5;66;03m# Child is launched. Close the parent's copy of those pipe\u001b[39;00m\n\u001b[32m   1560\u001b[39m     \u001b[38;5;66;03m# handles that only the child should have open.  You need\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1563\u001b[39m     \u001b[38;5;66;03m# pipe will not close when the child process exits and the\u001b[39;00m\n\u001b[32m   1564\u001b[39m     \u001b[38;5;66;03m# ReadFile will hang.\u001b[39;00m\n\u001b[32m   1565\u001b[39m     \u001b[38;5;28mself\u001b[39m._close_pipe_fds(p2cread, p2cwrite,\n\u001b[32m   1566\u001b[39m                          c2pread, c2pwrite,\n\u001b[32m   1567\u001b[39m                          errread, errwrite)\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [WinError 2] 지정된 파일을 찾을 수 없습니다"
     ]
    }
   ],
   "source": [
    "# ✅ 1. 필요한 라이브러리 로딩\n",
    "import pandas as pd\n",
    "import subprocess\n",
    "\n",
    "# ✅ 2. Knowledge Graph 로딩 및 텍스트 구성\n",
    "kg = pd.read_csv(\"kg_triples_test.csv\")\n",
    "kg[\"triple_text\"] = kg[\"subject\"] + \" \" + kg[\"predicate\"] + \" \" + kg[\"object\"]\n",
    "\n",
    "# ✅ 3. 테스트 질문 로딩\n",
    "test_df = pd.read_csv(\"test.csv\")\n",
    "\n",
    "# ✅ 4. KG 검색 함수\n",
    "def find_relevant_kg(user_input, kg_texts, topk=3):\n",
    "    return [t for t in kg_texts if any(word in user_input for word in t.split())][:topk]\n",
    "\n",
    "# ✅ 5. 프롬프트 생성 함수\n",
    "def build_prompt(user_input, kg_hits=None):\n",
    "    prompt = f\"질문: {user_input}\\n\"\n",
    "    if kg_hits:\n",
    "        prompt += \"배경지식:\\n\"\n",
    "        for hit in kg_hits:\n",
    "            prompt += f\"- {hit}\\n\"\n",
    "    prompt += \"답변:\"\n",
    "    return prompt\n",
    "\n",
    "# ✅ 6. 로컬 Ollama 모델 호출 함수 (예: llama3)\n",
    "def run_ollama(prompt, model=\"llama3\"):\n",
    "    result = subprocess.run(\n",
    "        [\"ollama\", \"run\", model],\n",
    "        input=prompt.encode(\"utf-8\"),\n",
    "        stdout=subprocess.PIPE,\n",
    "        stderr=subprocess.PIPE,\n",
    "        timeout=30\n",
    "    )\n",
    "    return result.stdout.decode(\"utf-8\").strip()\n",
    "\n",
    "# ✅ 7. 질문 입력 → KG 사용 여부에 따른 비교\n",
    "sample = test_df.sample(1, random_state=42)\n",
    "user_input = sample[\"sentence1\"].values[0]\n",
    "true_answer = sample[\"sentence2\"].values[0]\n",
    "\n",
    "kg_hits = find_relevant_kg(user_input, kg[\"triple_text\"])\n",
    "prompt_kg = build_prompt(user_input, kg_hits)\n",
    "prompt_no_kg = build_prompt(user_input)\n",
    "\n",
    "print(\"📌 질문:\", user_input)\n",
    "print(\"\\n[프롬프트 - KG 미사용]\\n\", prompt_no_kg)\n",
    "print(\"\\n[프롬프트 - KG 사용]\\n\", prompt_kg)\n",
    "\n",
    "# ✅ 8. Ollama 실행 및 출력 결과\n",
    "print(\"\\n🤖 [KG 미사용 답변]\\n\")\n",
    "print(run_ollama(prompt_no_kg))\n",
    "\n",
    "print(\"\\n🤖 [KG 사용 답변]\\n\")\n",
    "print(run_ollama(prompt_kg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c53429b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'KoBertTokenizer'. \n",
      "The class this function is called from is 'BertTokenizer'.\n",
      "Some weights of BertForMaskedLM were not initialized from the model checkpoint at monologg/kobert and are newly initialized: ['cls.predictions.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📌 KG 미사용:\n",
      "프롬프트: 질문: 질문: 나는 [MASK] 기분이다\n",
      "답변: 질문: 질문: 나는 꽉 기분이다\n",
      "\n",
      "📌 KG 사용:\n",
      "프롬프트: 질문: 질문: 나는 [MASK] 기분이다\n",
      "답변: 질문: 질문: 나는 꽉 기분이다\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizer, BertForMaskedLM\n",
    "import pandas as pd\n",
    "\n",
    "# CPU로 강제 설정\n",
    "device = torch.device(\"cpu\")\n",
    "torch.set_default_tensor_type(torch.FloatTensor)\n",
    "\n",
    "# KoBERT 모델과 토크나이저 로드\n",
    "tokenizer = BertTokenizer.from_pretrained('monologg/kobert')\n",
    "model = BertForMaskedLM.from_pretrained('monologg/kobert')\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "# KG 데이터 불러오기\n",
    "kg_df = pd.read_csv(\"kg_triples_test.csv\")\n",
    "if 'triple_text' not in kg_df.columns:\n",
    "    kg_df['triple_text'] = kg_df['subject'] + \" \" + kg_df['predicate'] + \" \" + kg_df['object']\n",
    "\n",
    "# 배경지식 찾기\n",
    "def find_relevant_kg(question, kg_df):\n",
    "    hits = []\n",
    "    for triple in kg_df['triple_text']:\n",
    "        if any(word in triple for word in question.split()):\n",
    "            hits.append(triple)\n",
    "    return hits[:3]\n",
    "\n",
    "# 프롬프트 생성\n",
    "def build_prompt(question, kg_hits=None):\n",
    "    prompt = \"\"\n",
    "    if kg_hits:\n",
    "        prompt += \"배경지식:\\n\"\n",
    "        for hit in kg_hits:\n",
    "            prompt += f\"- {hit}\\n\"\n",
    "    prompt += f\"질문: {question}\"\n",
    "    return prompt\n",
    "\n",
    "# 답변 생성\n",
    "def generate_answer(prompt):\n",
    "    if \"[MASK]\" not in prompt:\n",
    "        return \"질문에 [MASK]가 포함되어야 합니다.\"\n",
    "    \n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    \n",
    "    mask_token_index = torch.where(inputs[\"input_ids\"] == tokenizer.mask_token_id)[1]\n",
    "    mask_token_logits = outputs.logits[0, mask_token_index, :]\n",
    "    top_token = torch.argmax(mask_token_logits, dim=1)\n",
    "    predicted_token = tokenizer.decode(top_token)\n",
    "    \n",
    "    return prompt.replace(\"[MASK]\", predicted_token)\n",
    "\n",
    "# 사용자 입력\n",
    "user_question = input(\"질문을 입력하세요 (예: 나는 [MASK] 기분이다): \")\n",
    "\n",
    "# KG 미사용\n",
    "prompt_no_kg = build_prompt(user_question)\n",
    "answer_no_kg = generate_answer(prompt_no_kg)\n",
    "\n",
    "# KG 사용\n",
    "kg_hits = find_relevant_kg(user_question, kg_df)\n",
    "prompt_with_kg = build_prompt(user_question, kg_hits)\n",
    "answer_with_kg = generate_answer(prompt_with_kg)\n",
    "\n",
    "print(\"\\n KG 미사용:\")\n",
    "print(\"프롬프트:\", prompt_no_kg)\n",
    "print(\"답변:\", answer_no_kg)\n",
    "\n",
    "print(\"\\n KG 사용:\")\n",
    "print(\"프롬프트:\", prompt_with_kg)\n",
    "print(\"답변:\", answer_with_kg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "696c754e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📌 [KG 미사용 프롬프트]\n",
      " 질문: 피곤해\n",
      "답변:\n",
      "\n",
      "🤖 [KG 미사용 답변]\n",
      " ⏱️ 실행 시간이 초과되었습니다.\n",
      "\n",
      "📌 [KG 사용 프롬프트]\n",
      " 질문: 피곤해\n",
      "답변:\n",
      "\n",
      "🤖 [KG 사용 답변]\n",
      " ⏱️ 실행 시간이 초과되었습니다.\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "import pandas as pd\n",
    "\n",
    "# Ollama 실행 경로 (직접 지정)\n",
    "OLLAMA_PATH = r\"C:\\Users\\lsm40\\AppData\\Local\\Programs\\Ollama\\ollama.exe\"\n",
    "\n",
    "# 사용자 질문 입력\n",
    "user_input = input(\"질문을 입력하세요: \")\n",
    "\n",
    "# KG 파일 불러오기\n",
    "kg_df = pd.read_csv(\"kg_triples_test.csv\")  # 경로는 필요에 따라 수정\n",
    "\n",
    "# KG에서 관련 정보 추출 (간단한 키워드 기반 검색)\n",
    "def find_relevant_kg(question, kg_df):\n",
    "    hits = []\n",
    "    for idx, row in kg_df.iterrows():\n",
    "        triple = f\"{row['subject']}, {row['predicate']}, {row['object']}\"\n",
    "        if any(word in triple for word in question.split()):\n",
    "            hits.append(triple)\n",
    "    return hits[:3]  # 최대 3개까지만 사용\n",
    "\n",
    "# 프롬프트 생성\n",
    "def build_prompt(user_input, kg_hits=None):\n",
    "    prompt = \"\"\n",
    "    if kg_hits:\n",
    "        prompt += \"배경지식:\\n\"\n",
    "        for hit in kg_hits:\n",
    "            prompt += f\"- {hit}\\n\"\n",
    "    prompt += f\"질문: {user_input}\\n답변:\"\n",
    "    return prompt\n",
    "\n",
    "#  Llama3로 답변 생성\n",
    "def run_ollama(prompt, model=\"llama3\"):\n",
    "    try:\n",
    "        result = subprocess.run(\n",
    "            [OLLAMA_PATH, \"run\", model],\n",
    "            input=prompt.encode(\"utf-8\"),\n",
    "            stdout=subprocess.PIPE,\n",
    "            stderr=subprocess.PIPE,\n",
    "            timeout=60\n",
    "        )\n",
    "        return result.stdout.decode(\"utf-8\").strip()\n",
    "    except FileNotFoundError:\n",
    "        return \" Ollama 실행 파일을 찾을 수 없습니다. 경로를 다시 확인하세요.\"\n",
    "    except subprocess.TimeoutExpired:\n",
    "        return \" 실행 시간이 초과되었습니다.\"\n",
    "    except Exception as e:\n",
    "        return f\" 오류 발생: {e}\"\n",
    "\n",
    "#  KG 검색 결과 가져오기\n",
    "kg_hits = find_relevant_kg(user_input, kg_df)\n",
    "\n",
    "#  프롬프트 생성\n",
    "prompt_kg = build_prompt(user_input, kg_hits)\n",
    "prompt_no_kg = build_prompt(user_input)\n",
    "\n",
    "#  출력\n",
    "print(\"\\n [KG 미사용 프롬프트]\\n\", prompt_no_kg)\n",
    "print(\"\\n [KG 미사용 답변]\\n\", run_ollama(prompt_no_kg))\n",
    "\n",
    "print(\"\\n [KG 사용 프롬프트]\\n\", prompt_kg)\n",
    "print(\"\\n [KG 사용 답변]\\n\", run_ollama(prompt_kg))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51647132",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📌 [KG 미사용 프롬프트]\n",
      " 질문: 나 피곤해\n",
      "답변:\n",
      "\n",
      "🤖 [KG 미사용 답변]\n",
      " ⏱️ 실행 시간이 초과되었습니다.\n",
      "\n",
      "📌 [KG 사용 프롬프트]\n",
      " 질문: 나 피곤해\n",
      "답변:\n",
      "\n",
      "🤖 [KG 사용 답변]\n",
      " ⏱️ 실행 시간이 초과되었습니다.\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "#  Ollama 실행 파일 경로 (직접 확인된 경로로 수정 필요)\n",
    "OLLAMA_PATH = r\"C:\\Users\\lsm40\\AppData\\Local\\Programs\\Ollama\\ollama.exe\"\n",
    "\n",
    "#  사용자 질문 실시간 입력\n",
    "user_input = input(\"질문을 입력하세요: \").strip()\n",
    "\n",
    "#  KG 그래프 CSV 로딩 (컬럼명 자동 감지)\n",
    "kg_path = \"./kg_triples_test.csv\"  # 예: 'triple_text' 열이 있는 파일\n",
    "kg_df = pd.read_csv(kg_path)\n",
    "col = kg_df.columns[0]  # 첫 번째 열 자동 인식\n",
    "\n",
    "#  KG에서 관련된 배경지식 추출 함수\n",
    "def find_relevant_kg(question, df, column):\n",
    "    hits = []\n",
    "    for triple in df[column]:\n",
    "        if any(word in triple for word in question.split()):\n",
    "            hits.append(triple)\n",
    "    return hits[:3]\n",
    "\n",
    "#  프롬프트 생성 함수\n",
    "def build_prompt(question, kg_hits=None):\n",
    "    prompt = \"\"\n",
    "    if kg_hits:\n",
    "        prompt += \"배경지식:\\n\"\n",
    "        for hit in kg_hits:\n",
    "            prompt += f\"- {hit}\\n\"\n",
    "    prompt += f\"질문: {question}\\n답변:\"\n",
    "    return prompt\n",
    "\n",
    "#  Llama3 실행 함수\n",
    "def run_ollama(prompt, timeout=60):\n",
    "    try:\n",
    "        result = subprocess.run(\n",
    "            [OLLAMA_PATH, \"run\", \"llama3\"],\n",
    "            input=prompt.encode(\"utf-8\"),\n",
    "            stdout=subprocess.PIPE,\n",
    "            stderr=subprocess.PIPE,\n",
    "            timeout=timeout\n",
    "        )\n",
    "        if result.stderr:\n",
    "            print(\" stderr:\", result.stderr.decode(\"utf-8\").strip())\n",
    "        return result.stdout.decode(\"utf-8\").strip()\n",
    "    except subprocess.TimeoutExpired:\n",
    "        return \" 실행 시간이 초과되었습니다.\"\n",
    "    except FileNotFoundError:\n",
    "        return \" Ollama 실행 파일을 찾을 수 없습니다. 경로를 확인하세요.\"\n",
    "\n",
    "#  KG 기반 프롬프트 구성\n",
    "kg_hits = find_relevant_kg(user_input, kg_df, col)\n",
    "prompt_no_kg = build_prompt(user_input)\n",
    "prompt_kg = build_prompt(user_input, kg_hits)\n",
    "\n",
    "#  실행 및 결과 출력\n",
    "print(\"\\n [KG 미사용 프롬프트]\\n\", prompt_no_kg)\n",
    "print(\"\\n [KG 미사용 답변]\\n\", run_ollama(prompt_no_kg))\n",
    "\n",
    "print(\"\\n [KG 사용 프롬프트]\\n\", prompt_kg)\n",
    "print(\"\\n [KG 사용 답변]\\n\", run_ollama(prompt_kg))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e98a60b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'KoBertTokenizer'. \n",
      "The class this function is called from is 'BertTokenizer'.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "With n_samples=0, test_size=0.2 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[40]\u001b[39m\u001b[32m, line 71\u001b[39m\n\u001b[32m     68\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m item\n\u001b[32m     70\u001b[39m \u001b[38;5;66;03m# ✅ 데이터 분리 (8:2), stratify 가능\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m71\u001b[39m train_df, test_df = \u001b[43mtrain_test_split\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     72\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     73\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtest_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     74\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstratify\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlabel\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     75\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m42\u001b[39;49m\n\u001b[32m     76\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     78\u001b[39m \u001b[38;5;66;03m# ✅ 모델 정의\u001b[39;00m\n\u001b[32m     79\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget_model\u001b[39m():\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\User\\lsm40\\anaconda3\\envs\\min24\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:216\u001b[39m, in \u001b[36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    210\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    211\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m    212\u001b[39m         skip_parameter_validation=(\n\u001b[32m    213\u001b[39m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m    214\u001b[39m         )\n\u001b[32m    215\u001b[39m     ):\n\u001b[32m--> \u001b[39m\u001b[32m216\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    217\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    218\u001b[39m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[32m    219\u001b[39m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[32m    220\u001b[39m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[32m    221\u001b[39m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[32m    222\u001b[39m     msg = re.sub(\n\u001b[32m    223\u001b[39m         \u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[33m\\\u001b[39m\u001b[33mw+ must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    224\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc.\u001b[34m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    225\u001b[39m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[32m    226\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\User\\lsm40\\anaconda3\\envs\\min24\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:2851\u001b[39m, in \u001b[36mtrain_test_split\u001b[39m\u001b[34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[39m\n\u001b[32m   2848\u001b[39m arrays = indexable(*arrays)\n\u001b[32m   2850\u001b[39m n_samples = _num_samples(arrays[\u001b[32m0\u001b[39m])\n\u001b[32m-> \u001b[39m\u001b[32m2851\u001b[39m n_train, n_test = \u001b[43m_validate_shuffle_split\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2852\u001b[39m \u001b[43m    \u001b[49m\u001b[43mn_samples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdefault_test_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.25\u001b[39;49m\n\u001b[32m   2853\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2855\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m shuffle \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[32m   2856\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m stratify \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\User\\lsm40\\anaconda3\\envs\\min24\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:2481\u001b[39m, in \u001b[36m_validate_shuffle_split\u001b[39m\u001b[34m(n_samples, test_size, train_size, default_test_size)\u001b[39m\n\u001b[32m   2478\u001b[39m n_train, n_test = \u001b[38;5;28mint\u001b[39m(n_train), \u001b[38;5;28mint\u001b[39m(n_test)\n\u001b[32m   2480\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m n_train == \u001b[32m0\u001b[39m:\n\u001b[32m-> \u001b[39m\u001b[32m2481\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   2482\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mWith n_samples=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m, test_size=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m and train_size=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m, the \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2483\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mresulting train set will be empty. Adjust any of the \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2484\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33maforementioned parameters.\u001b[39m\u001b[33m\"\u001b[39m.format(n_samples, test_size, train_size)\n\u001b[32m   2485\u001b[39m     )\n\u001b[32m   2487\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m n_train, n_test\n",
      "\u001b[31mValueError\u001b[39m: With n_samples=0, test_size=0.2 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from torch.optim import AdamW\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import json\n",
    "\n",
    "# ✅ KoBERT 로드\n",
    "model_name = 'monologg/kobert'\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "device = torch.device(\"cpu\")\n",
    "\n",
    "# ✅ 데이터셋 불러오기\n",
    "def load_jsonl(path):\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        return [json.loads(line) for line in f]\n",
    "\n",
    "data = load_jsonl(\"poetry.jsonl\")\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# ✅ 라벨 인코딩: \"human\" → 0, \"ai\" → 1\n",
    "label_map = {\"human\": 0, \"ai\": 1}\n",
    "df['label'] = df['label'].map(label_map)\n",
    "\n",
    "# ✅ NaN 제거 (매핑되지 않은 라벨 있는 행 제거)\n",
    "df = df.dropna(subset=['label'])\n",
    "df['label'] = df['label'].astype(int)\n",
    "\n",
    "# ✅ KG 불러오기\n",
    "kg_df = pd.read_csv(\"kg_triples_test.csv\")\n",
    "kg_texts = (\n",
    "    kg_df\n",
    "    .apply(lambda row: f\"{row['subject']} {row['predicate']} {row['object']}\", axis=1)\n",
    "    .tolist()\n",
    ")\n",
    "\n",
    "# ✅ KG 관련 배경지식 찾기 (간단 키워드 매칭)\n",
    "def find_relevant_kg(text, kg_texts, topk=3):\n",
    "    hits = [kg for kg in kg_texts if any(word in kg for word in text.split())]\n",
    "    return \" \".join(hits[:topk])\n",
    "\n",
    "# ✅ PyTorch Dataset\n",
    "class PoetryDataset(Dataset):\n",
    "    def __init__(self, dataframe, use_kg=False):\n",
    "        self.data = dataframe.reset_index(drop=True)\n",
    "        self.use_kg = use_kg\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.data.iloc[idx]\n",
    "        text = row['text']\n",
    "        if self.use_kg:\n",
    "            kg = find_relevant_kg(text, kg_texts)\n",
    "            text = f\"{text} [SEP] {kg}\"\n",
    "        inputs = tokenizer(\n",
    "            text,\n",
    "            padding='max_length',\n",
    "            max_length=128,\n",
    "            truncation=True,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "        item = {k: v.squeeze(0) for k, v in inputs.items()}\n",
    "        item[\"labels\"] = torch.tensor(row[\"label\"], dtype=torch.long)\n",
    "        return item\n",
    "\n",
    "# ✅ 데이터 분리 (8:2), stratify 가능\n",
    "train_df, test_df = train_test_split(\n",
    "    df,\n",
    "    test_size=0.2,\n",
    "    stratify=df[\"label\"],\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# ✅ 모델 정의\n",
    "def get_model():\n",
    "    return BertForSequenceClassification.from_pretrained(\n",
    "        model_name,\n",
    "        num_labels=2\n",
    "    ).to(device)\n",
    "\n",
    "# ✅ 학습 함수\n",
    "def train_model(model, train_loader, epochs=3):\n",
    "    optimizer = AdamW(model.parameters(), lr=5e-5)\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        for batch in train_loader:\n",
    "            batch = {k: v.to(device) for k, v in batch.items()}\n",
    "            outputs = model(**batch)\n",
    "            loss = outputs.loss\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "        print(f\"Epoch {epoch+1} 완료\")\n",
    "\n",
    "# ✅ 평가 함수\n",
    "def evaluate(model, test_loader):\n",
    "    model.eval()\n",
    "    preds, labels = [], []\n",
    "    with torch.no_grad():\n",
    "        for batch in test_loader:\n",
    "            batch = {k: v.to(device) for k, v in batch.items()}\n",
    "            outputs = model(**batch)\n",
    "            logits = outputs.logits\n",
    "            preds += torch.argmax(logits, axis=1).cpu().tolist()\n",
    "            labels += batch[\"labels\"].cpu().tolist()\n",
    "    print(classification_report(labels, preds, target_names=[\"human\", \"ai\"]))\n",
    "\n",
    "\n",
    "# ---- KG 미사용 실험 ----\n",
    "model = get_model()\n",
    "train_loader_no_kg = DataLoader(\n",
    "    PoetryDataset(train_df, use_kg=False),\n",
    "    batch_size=8,\n",
    "    shuffle=True\n",
    ")\n",
    "test_loader_no_kg = DataLoader(\n",
    "    PoetryDataset(test_df, use_kg=False),\n",
    "    batch_size=8\n",
    ")\n",
    "\n",
    "print(\"🔥 KG 미사용 학습 시작\")\n",
    "train_model(model, train_loader_no_kg)\n",
    "print(\"📊 KG 미사용 성능\")\n",
    "evaluate(model, test_loader_no_kg)\n",
    "\n",
    "\n",
    "# ---- KG 사용 실험 ----\n",
    "model = get_model()\n",
    "train_loader_kg = DataLoader(\n",
    "    PoetryDataset(train_df, use_kg=True),\n",
    "    batch_size=8,\n",
    "    shuffle=True\n",
    ")\n",
    "test_loader_kg = DataLoader(\n",
    "    PoetryDataset(test_df, use_kg=True),\n",
    "    batch_size=8\n",
    ")\n",
    "\n",
    "print(\"\\n🔥 KG 사용 학습 시작\")\n",
    "train_model(model, train_loader_kg)\n",
    "print(\"📊 KG 사용 성능\")\n",
    "evaluate(model, test_loader_kg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f21f6ede",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❓ 로드 후 샘플 수: 945\n",
      "❓ 라벨 분포 (로드 직후):\n",
      " label\n",
      "1    756\n",
      "0    189\n",
      "Name: count, dtype: int64\n",
      "✅ 정제 후 샘플 수: 945\n",
      "❓ 라벨 분포 (정제 후):\n",
      " label\n",
      "1    756\n",
      "0    189\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'KoBertTokenizer'. \n",
      "The class this function is called from is 'BertTokenizer'.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at monologg/kobert and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔥 KG 미사용 학습 시작\n",
      "Epoch 1 완료\n",
      "Epoch 2 완료\n",
      "Epoch 3 완료\n",
      "📊 KG 미사용 결과\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\User\\lsm40\\anaconda3\\envs\\min24\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "d:\\User\\lsm40\\anaconda3\\envs\\min24\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "d:\\User\\lsm40\\anaconda3\\envs\\min24\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       human       0.00      0.00      0.00        38\n",
      "          ai       0.80      1.00      0.89       151\n",
      "\n",
      "    accuracy                           0.80       189\n",
      "   macro avg       0.40      0.50      0.44       189\n",
      "weighted avg       0.64      0.80      0.71       189\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at monologg/kobert and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔥 KG 사용 학습 시작\n",
      "Epoch 1 완료\n",
      "Epoch 2 완료\n",
      "Epoch 3 완료\n",
      "📊 KG 사용 결과\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       human       0.00      0.00      0.00        38\n",
      "          ai       0.80      1.00      0.89       151\n",
      "\n",
      "    accuracy                           0.80       189\n",
      "   macro avg       0.40      0.50      0.44       189\n",
      "weighted avg       0.64      0.80      0.71       189\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\User\\lsm40\\anaconda3\\envs\\min24\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "d:\\User\\lsm40\\anaconda3\\envs\\min24\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "d:\\User\\lsm40\\anaconda3\\envs\\min24\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from torch.optim import AdamW\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import json\n",
    "\n",
    "# 1) 데이터 로드\n",
    "def load_jsonl(path):\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        return [json.loads(line) for line in f]\n",
    "data = load_jsonl(\"poetry.jsonl\")\n",
    "df = pd.DataFrame(data)\n",
    "print(\"❓ 로드 후 샘플 수:\", len(df))\n",
    "print(\"❓ 라벨 분포 (로드 직후):\\n\", df['label'].value_counts())\n",
    "\n",
    "# 2) 문자열 'human'/'ai' → 0/1 매핑 (이미 숫자면 건너뛰기)\n",
    "label_map = {\"human\": 0, \"ai\": 1}\n",
    "if df['label'].dtype == object:\n",
    "    df['label'] = df['label'].map(label_map)\n",
    "\n",
    "# 3) 숫자형으로 변환 & 0·1 외 나머지(NaN 포함) 삭제\n",
    "df['label'] = pd.to_numeric(df['label'], errors='coerce').astype('Int64')\n",
    "df = df[df['label'].isin([0, 1])].reset_index(drop=True)\n",
    "df['label'] = df['label'].astype(int)\n",
    "\n",
    "print(\"✅ 정제 후 샘플 수:\", len(df))\n",
    "print(\"❓ 라벨 분포 (정제 후):\\n\", df['label'].value_counts())\n",
    "\n",
    "# 4) KG 불러오기\n",
    "kg_df = pd.read_csv(\"kg_triples_test.csv\")\n",
    "kg_texts = (\n",
    "    kg_df\n",
    "    .apply(lambda r: f\"{r['subject']} {r['predicate']} {r['object']}\", axis=1)\n",
    "    .tolist()\n",
    ")\n",
    "def find_relevant_kg(text, kg_texts, topk=3):\n",
    "    hits = [kg for kg in kg_texts if any(tok in kg for tok in text.split())]\n",
    "    return \" \".join(hits[:topk])\n",
    "\n",
    "# 5) Dataset 정의\n",
    "class PoetryDataset(Dataset):\n",
    "    def __init__(self, df, tokenizer, use_kg=False):\n",
    "        self.df = df\n",
    "        self.tokenizer = tokenizer\n",
    "        self.use_kg = use_kg\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.df.iloc[idx]['text']\n",
    "        if self.use_kg:\n",
    "            kg = find_relevant_kg(text, kg_texts)\n",
    "            text = f\"{text} [SEP] {kg}\"\n",
    "        inputs = self.tokenizer(\n",
    "            text,\n",
    "            padding='max_length',\n",
    "            max_length=128,\n",
    "            truncation=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        item = {k: v.squeeze(0) for k, v in inputs.items()}\n",
    "        item['labels'] = torch.tensor(self.df.iloc[idx]['label'], dtype=torch.long)\n",
    "        return item\n",
    "\n",
    "# 6) 데이터 분리\n",
    "train_df, test_df = train_test_split(\n",
    "    df, test_size=0.2, stratify=df['label'], random_state=42\n",
    ")\n",
    "\n",
    "# 7) 토크나이저 및 모델 준비\n",
    "model_name = 'monologg/kobert'\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "device = torch.device(\"cpu\")\n",
    "def get_model():\n",
    "    return BertForSequenceClassification.from_pretrained(\n",
    "        model_name, num_labels=2\n",
    "    ).to(device)\n",
    "\n",
    "# 8) 학습/평가 함수\n",
    "def train_model(model, loader, epochs=3):\n",
    "    optim = AdamW(model.parameters(), lr=5e-5)\n",
    "    model.train()\n",
    "    for e in range(epochs):\n",
    "        for batch in loader:\n",
    "            batch = {k: v.to(device) for k, v in batch.items()}\n",
    "            loss = model(**batch).loss\n",
    "            loss.backward()\n",
    "            optim.step(); optim.zero_grad()\n",
    "        print(f\"Epoch {e+1} 완료\")\n",
    "\n",
    "def evaluate(model, loader):\n",
    "    model.eval()\n",
    "    preds, labs = [], []\n",
    "    with torch.no_grad():\n",
    "        for batch in loader:\n",
    "            batch = {k: v.to(device) for k, v in batch.items()}\n",
    "            logits = model(**batch).logits\n",
    "            preds += torch.argmax(logits, axis=1).cpu().tolist()\n",
    "            labs  += batch['labels'].cpu().tolist()\n",
    "    print(classification_report(labs, preds, target_names=['human','ai']))\n",
    "\n",
    "# 9) KG 미사용\n",
    "model = get_model()\n",
    "dl_train = DataLoader(PoetryDataset(train_df, tokenizer, use_kg=False),\n",
    "                      batch_size=8, shuffle=True)\n",
    "dl_test  = DataLoader(PoetryDataset(test_df,  tokenizer, use_kg=False),\n",
    "                      batch_size=8)\n",
    "print(\"🔥 KG 미사용 학습 시작\")\n",
    "train_model(model, dl_train)\n",
    "print(\"📊 KG 미사용 결과\")\n",
    "evaluate(model, dl_test)\n",
    "\n",
    "# 10) KG 사용\n",
    "model = get_model()\n",
    "dl_train = DataLoader(PoetryDataset(train_df, tokenizer, use_kg=True),\n",
    "                      batch_size=8, shuffle=True)\n",
    "dl_test  = DataLoader(PoetryDataset(test_df,  tokenizer, use_kg=True),\n",
    "                      batch_size=8)\n",
    "print(\"\\n🔥 KG 사용 학습 시작\")\n",
    "train_model(model, dl_train)\n",
    "print(\"📊 KG 사용 결과\")\n",
    "evaluate(model, dl_test)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "min24",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
