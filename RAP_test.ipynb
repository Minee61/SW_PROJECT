{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cf96b506",
   "metadata": {},
   "source": [
    "# ë°ì´í„° ì…‹ ê°€ì ¸ì˜¤ê¸°\n",
    "\n",
    "# RAP êµ¬ì¡° \n",
    "\"í…ìŠ¤íŠ¸ ë¬¸ì¥\" + [Triple] (ì—”í‹°í‹°1, ê´€ê³„, ì—”í‹°í‹°2) \n",
    "ìˆ¨ì€ ì˜ë¯¸ ì°¾ê¸° "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c0ca5fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "\n",
    "train = pd.read_csv(\"train.csv\")\n",
    "test = pd.read_csv(\"test.csv\")\n",
    "\n",
    "hint = \"[Hint] ê¸°ê³„ëŠ” ê°ì •ì´ ë‹¤ì±„ë¡­ê²Œ, ì‚¬ëŒì€ ê°ì •ì´ ë¹„ìŠ·í•˜ê²Œ í‘œí˜„í˜„\"\n",
    "\n",
    "train[\"text\"] = train[\"sentence1\"] + \" \" + hint\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "529749ad",
   "metadata": {},
   "source": [
    "## ë°ì´í„° ë¶„í•  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "17a6b7c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "feature_train, feature_test, target_train, target_test = train_test_split(\n",
    "    train[\"text\"], train[\"label\"], test_size=0.2, stratify=train[\"label\"], random_state=42\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b57197b",
   "metadata": {},
   "source": [
    "# ì „ì²˜ë¦¬ / ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸° "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0cb61257",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:00<00:00, 6422.15 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:00<00:00, 2667.11 examples/s]\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at klue/roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from transformers import TrainingArguments, Trainer\n",
    "from datasets import Dataset\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"klue/roberta-base\")\n",
    "\n",
    "train_dataset = Dataset.from_pandas(pd.DataFrame({\"text\": feature_train, \"label\": target_train}))\n",
    "test_dataset = Dataset.from_pandas(pd.DataFrame({\"text\": feature_test, \"label\": target_test}))\n",
    "\n",
    "def preprocess(examples):\n",
    "    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True, max_length=256)\n",
    "\n",
    "train_dataset = train_dataset.map(preprocess, batched=True)\n",
    "test_dataset = test_dataset.map(preprocess, batched=True)\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"klue/roberta-base\", num_labels=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2e4b6334",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ficl/cuda-env/lib/python3.8/site-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ğŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      " 22%|â–ˆâ–ˆâ–       | 2/9 [00:00<00:00, 12.94it/s]\n",
      " 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 4/9 [00:00<00:00, 12.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.408050537109375, 'eval_runtime': 0.024, 'eval_samples_per_second': 417.489, 'eval_steps_per_second': 41.749, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 6/9 [00:00<00:00, 13.95it/s]\n",
      " 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 8/9 [00:00<00:00, 12.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.3799073696136475, 'eval_runtime': 0.0232, 'eval_samples_per_second': 431.269, 'eval_steps_per_second': 43.127, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:01<00:00,  4.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.3796817064285278, 'eval_runtime': 0.0191, 'eval_samples_per_second': 523.039, 'eval_steps_per_second': 52.304, 'epoch': 3.0}\n",
      "{'train_runtime': 1.8801, 'train_samples_per_second': 63.827, 'train_steps_per_second': 4.787, 'train_loss': 1.3950748443603516, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=9, training_loss=1.3950748443603516, metrics={'train_runtime': 1.8801, 'train_samples_per_second': 63.827, 'train_steps_per_second': 4.787, 'total_flos': 15787088547840.0, 'train_loss': 1.3950748443603516, 'epoch': 3.0})"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "training_args =TrainingArguments(\n",
    "                                   output_dir =\"./results\"\n",
    "                                 , evaluation_strategy=\"epoch\"\n",
    "                                 , logging_dir=\"./logs\"\n",
    "                                 , per_device_eval_batch_size=16\n",
    "                                 , per_device_train_batch_size=16\n",
    "                                 , num_train_epochs=3\n",
    "                                 , learning_rate=5e-5 ,)\n",
    "trainer = Trainer(\n",
    "                    model = model\n",
    "                    , args=training_args\n",
    "                    , train_dataset=train_dataset\n",
    "                    , eval_dataset = test_dataset )\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8423cc9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 4275.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.40      1.00      0.57         4\n",
      "           3       0.00      0.00      0.00         2\n",
      "           4       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.40        10\n",
      "   macro avg       0.10      0.25      0.14        10\n",
      "weighted avg       0.16      0.40      0.23        10\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/home/ficl/cuda-env/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/ficl/cuda-env/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/ficl/cuda-env/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# ì˜ˆì¸¡ ë° í‰ê°€\n",
    "preds = trainer.predict(test_dataset)\n",
    "y_pred = np.argmax(preds.predictions, axis=1)\n",
    "\n",
    "print(\"result\")\n",
    "print(classification_report(target_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cuda-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
