RAP 실습 구성 

# 문장 정리 방법
- text_each : 하나의 문장만 사용한다. 
- text_all : 4개 문장 모두다 사용한다. 
- text_pair_12 : 앞에 두 문장만 사용
- text_pair_34 : 뒤에 두 문장만 사용
- text_with_kg : RAP 형태 문장 지식 추가 

# 데이터셋 준비 방법
- train_test_split : 학습/테스트 나누기
- HuggingFace Dataset : Trainer용 데이터셋 나누기 

# 전처리 종류 
- Tokenizer : 문장을 토큰 단위로 쪼개기  
- truncation : 긴 문장은 자르기 
- padding : 길이를 다 일정하게 맞춤
- cleaning :특수 문자 제거 
- hint  : 지식 문장 추가 (RAP 쓸 때 사용) 

# LLM 모델 종류 
- BERT 
- RoBERTa
- DistilBERT
- Electra
- DeBERTa

# 하이퍼파라미터 
- 기본값
- 설정값 

# 파인튜닝 종류 
- Classification Fine-tune : 분류 파인튜닝 ( 클래스 분류 )
- Prompt-based Fine-tune : 질문 하듯이 말해주는 형식 
- Multi-task Fine-tune
- RAG-style Fine-tune : 관계를 반영해주는 방식 

# 성능 평가 
- 정확도 : 전체 중 맞춘 비율
- 정밀도 : AI라고 예측한 것 중 진짜 AI 비율 
- 재현율 : 실제 AI 문장 중 AI라고 맞춘 비율  
- F1-score : 정밀도 + 재현율의 조화 
- Confusion Matrix : 클래스별 정답, 오답 개수 

RAP 사용 
-> 문장을 받기 
-> 관련 관계지식과 문서를 함께 넣기 
-> 모델이 이것을 동시에 보고 판단 

소규모 커스텀 KG를 만들기?
LLM을 이용해서 KG를 자동으로 구축한 후 

 1. LLM으로 KG후보 생성 
 사람이 직접 필터링 해서 진짜 KG만 남김
 
 2. LLM이 생성만 문장을 생성, 
 	NLP 분석기 이용 : triple 추출 : 관계, 객체 형식으로 추출 
 	형식화된 KNOWLEDGE Graph 로 바꿈
 	(정규식, 패턴, score로 필터링 필요)
 	
 3. 위키 데이터, ConceptNet, DBpedia 같은 신뢰 가능한 외부 KG랑 비교 검증 

