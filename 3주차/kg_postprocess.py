# -*- coding: utf-8 -*-
"""
kg_postprocess.py
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ì…ë ¥:  triples.csv   (subject,predicate,object,src_url)
ì¶œë ¥: triples_clean.csv (subject_id,predicate,object_clean,src_url)

ğŸ“Œ ê¸°ëŠ¥
    1) **subject ì¤‘ë³µ í•´ê²°**  â†’ src_url ì˜ MD5 í•´ì‹œ 8ìë¥¼ subject_id ë¡œ ì‚¬ìš©
    2) **object ì •ì œ**        â†’ Okt í˜•íƒœì†Œ ë¶„ì„ í›„ 2~4ì ëª…ì‚¬ ì¶”ì¶œ, ì¤‘ë³µ ì œê±°, ìµœëŒ€ 3ê°œ
    3) **predicate ì¬ë§¤í•‘**   â†’ objectÂ·subject í‚¤ì›Œë“œì— ê¸°ë°˜í•œ ê°„ë‹¨ ë£° (origin_of, subtype_of, ...)
    4) CSV ì €ì¥ + ìš”ì•½ ì¶œë ¥

í•„ìˆ˜:  pip install pandas konlpy sklearn tqdm
ì˜ˆì‹œ:   python kg_postprocess.py triples.csv triples_clean.csv
"""

import sys, csv, hashlib, re, pathlib
import pandas as pd
from konlpy.tag import Okt
from sklearn.feature_extraction.text import TfidfVectorizer
from tqdm import tqdm

if len(sys.argv) < 3:
    sys.exit("Usage: python kg_postprocess.py <input_csv> <output_csv>")

IN_CSV, OUT_CSV = map(pathlib.Path, sys.argv[1:3])

df = pd.read_csv(IN_CSV)
okt = Okt()

# 1) subject_id (url hash)
df["subject_id"] = df["src_url"].apply(lambda u: hashlib.md5(u.encode()).hexdigest()[:8])

# 2) object ì •ì œ í•¨ìˆ˜
def clean_object(text: str) -> str:
    nouns = [n for n in okt.nouns(str(text)) if 2 <= len(n) <= 4]
    nouns = list(dict.fromkeys(nouns))          # ì¤‘ë³µ ì œê±° (order keep)
    return " ".join(nouns[:3])

df["object_clean"] = df["object"].apply(clean_object)

# 3) predicate ì¬ë§¤í•‘ ë£°
rules = [
    (re.compile(r"ìœ ë˜|ê¸°ì›|ë°œìƒ"), "origin_of"),
    (re.compile(r"êµ¬ë¶„|ë‚˜ë‰˜"), "subtype_of"),
    (re.compile(r"ë°˜ëŒ€|ìƒë°˜"), "opposite_to"),
    (re.compile(r"ì˜ˆ"), "example_of"),
    (re.compile(r"ë‹¤ë¥´ê²Œ|êµ¬ë³„"), "contrast_with"),
    (re.compile(r"í¬í•¨|ì†í•˜"), "includes"),
]

def remap_pred(row):
    txt = f"{row['subject']} {row['object']}"
    for pat, tag in rules:
        if pat.search(txt):
            return tag
    return row["predicate"] or "defines"

df["predicate_new"] = df.apply(remap_pred, axis=1)

# 4) ì¤‘ë³µ ì œê±°
final_cols = ["subject_id", "predicate_new", "object_clean", "src_url"]
clean_df = df[final_cols].drop_duplicates()

clean_df.columns = ["subject", "predicate", "object", "src_url"]
clean_df.to_csv(OUT_CSV, index=False, quoting=csv.QUOTE_MINIMAL)

print(f"âœ… saved {len(clean_df)} rows â†’ {OUT_CSV.resolve()}")
